{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8Y9AfHalhbK",
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Импорт\" data-toc-modified-id=\"Импорт-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Импорт</a></span></li><li><span><a href=\"#Описание\" data-toc-modified-id=\"Описание-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Описание</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Классификация-с-помощью-Bag-of-words\" data-toc-modified-id=\"Классификация-с-помощью-Bag-of-words-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Классификация с помощью Bag of words</a></span><ul class=\"toc-item\"><li><span><a href=\"#Модель-логистической-регресии\" data-toc-modified-id=\"Модель-логистической-регресии-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Модель логистической регресии</a></span></li><li><span><a href=\"#Модель-случайного-леса\" data-toc-modified-id=\"Модель-случайного-леса-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Модель случайного леса</a></span></li><li><span><a href=\"#Модель-градиентного-спуска\" data-toc-modified-id=\"Модель-градиентного-спуска-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Модель градиентного спуска</a></span></li><li><span><a href=\"#Сравнение-и-проверка-на-тестовой-выборке\" data-toc-modified-id=\"Сравнение-и-проверка-на-тестовой-выборке-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Сравнение и проверка на тестовой выборке</a></span></li></ul></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUz7949klhbO"
   },
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEkARajPlhbP"
   },
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75.\n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели.\n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B76VnmawlhbQ"
   },
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gReDiqWglhbQ"
   },
   "source": [
    "### Импорт"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9gyyrf7lhbR"
   },
   "source": [
    "Импортируем необходимые для работы библиотеки. Считаем данные из csv-файла в датафрейм, сохраним в переменную `data` и выведем на экран первые десять строк и общую информацию о датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T21:40:59.622763Z",
     "iopub.status.busy": "2023-07-26T21:40:59.622496Z",
     "iopub.status.idle": "2023-07-26T21:41:15.653335Z",
     "shell.execute_reply": "2023-07-26T21:41:15.652304Z",
     "shell.execute_reply.started": "2023-07-26T21:40:59.622738Z"
    },
    "id": "LfcmjX4QlhbS",
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# miscellaneous\n",
    "import pickle\n",
    "\n",
    "# data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV, \n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    train_test_split\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import lightgbm as lgb\n",
    "\n",
    "# nlp\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import re\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "execution": {
     "iopub.execute_input": "2023-07-26T21:41:15.656504Z",
     "iopub.status.busy": "2023-07-26T21:41:15.655430Z",
     "iopub.status.idle": "2023-07-26T21:41:21.339852Z",
     "shell.execute_reply": "2023-07-26T21:41:21.338731Z",
     "shell.execute_reply.started": "2023-07-26T21:41:15.656465Z"
    },
    "id": "Wh5rKnEOlhbT",
    "outputId": "e1ffa68f-9e85-4fd8-e32e-d868ac885585"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "159446  \":::::And for the second time of asking, when ...      0\n",
       "159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159449  And it looks like it was actually you who put ...      0\n",
       "159450  \"\\nAnd ... I really don't think you understand...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# испльзуем опцию index_col, чтобы не создавать дубликат столбца с индексами\n",
    "try:\n",
    "    data = pd.read_csv(\n",
    "        'https://code.s3.yandex.net/datasets/toxic_comments.csv',\n",
    "        index_col=0)\n",
    "except:\n",
    "    data = pd.read_csv(\n",
    "        'toxic_comments.csv',\n",
    "        index_col=0)\n",
    "\n",
    "pd.concat([data.head(5), data.tail(5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRCfyFzylhbU"
   },
   "source": [
    "### Описание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fc8rI21rlhbV"
   },
   "source": [
    "Выведем общую информацию о датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-26T21:41:21.341789Z",
     "iopub.status.busy": "2023-07-26T21:41:21.341405Z",
     "iopub.status.idle": "2023-07-26T21:41:21.408640Z",
     "shell.execute_reply": "2023-07-26T21:41:21.407605Z",
     "shell.execute_reply.started": "2023-07-26T21:41:21.341739Z"
    },
    "id": "y8oqvPKrlhbV",
    "outputId": "077bc183-53ef-4fc8-80f4-69f47d407c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5F1N1DRhlhbV"
   },
   "source": [
    "В датасете 2 признака и 159292 объектов. Типы данных в порядке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rc3VEKswlhbV"
   },
   "source": [
    "Признаки:\n",
    "- `text` — текст комментария на английском языке;\n",
    "\n",
    "Целевой признак:\n",
    "- `toxic` — является ли комментарий токсичным (1 — да, 0 — нет), бинарный категориальный признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "execution": {
     "iopub.execute_input": "2023-07-26T21:41:21.411934Z",
     "iopub.status.busy": "2023-07-26T21:41:21.411547Z",
     "iopub.status.idle": "2023-07-26T21:41:21.437451Z",
     "shell.execute_reply": "2023-07-26T21:41:21.436312Z",
     "shell.execute_reply.started": "2023-07-26T21:41:21.411898Z"
    },
    "id": "pfE12_vZlhbW",
    "outputId": "97cde42a-f57f-4bff-e5ad-c26f6b9926a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>159292.0</td>\n",
       "      <td>0.101612</td>\n",
       "      <td>0.302139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean       std  min  25%  50%  75%  max\n",
       "toxic  159292.0  0.101612  0.302139  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "execution": {
     "iopub.execute_input": "2023-07-26T21:41:21.439618Z",
     "iopub.status.busy": "2023-07-26T21:41:21.439238Z",
     "iopub.status.idle": "2023-07-26T21:41:21.625179Z",
     "shell.execute_reply": "2023-07-26T21:41:21.623970Z",
     "shell.execute_reply.started": "2023-07-26T21:41:21.439582Z"
    },
    "id": "NYR2aLAUlhbW",
    "outputId": "8746dd1e-938f-4d2e-fdd6-014f97da1e35",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>159292</td>\n",
       "      <td>159292</td>\n",
       "      <td>here are a bunch of other images of the tree o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  unique                                                top freq\n",
       "text  159292  159292  here are a bunch of other images of the tree o...    1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include=['O']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HC2zYwilhbX"
   },
   "source": [
    "Пропусков и явных дубликатов нет. значения `toxic` выглядят адекватными. В выборке присутствует дисбаланс классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUcKNPwETqgx"
   },
   "source": [
    "Создадим тренировочную, валидационную и тестовую выборки. Дисбаланс классов учтем при обучении модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Количество токсичных комментариев</th>\n",
       "      <th>Общее количество комментариев</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>9712</td>\n",
       "      <td>95575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>3237</td>\n",
       "      <td>31859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3237</td>\n",
       "      <td>31858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Количество токсичных комментариев  Общее количество комментариев\n",
       "train                               9712                          95575\n",
       "valid                               3237                          31859\n",
       "test                                3237                          31858"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сплит на 0.6 и 0.4, 0.6 уходит в переменные train, 0.4 в temp\n",
    "train, temp = train_test_split(\n",
    "    data, test_size=0.4, random_state=42, stratify=data['toxic'])\n",
    "\n",
    "# сплит на 0.5 и 0.5 из переменной temp\n",
    "test, valid = train_test_split(\n",
    "    temp, test_size=0.5, random_state=42, stratify=temp['toxic'])\n",
    "\n",
    "toxic = []\n",
    "full = []\n",
    "for i in [train, valid, test]:\n",
    "    toxic.append(i['toxic'].sum())\n",
    "    full.append(i.shape[0])\n",
    "\n",
    "pd.DataFrame(\n",
    "    {'Количество токсичных комментариев':toxic,\n",
    "     'Общее количество комментариев':full\n",
    "    },\n",
    "    index=['train', 'valid', 'test']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbLccIfXklrK"
   },
   "source": [
    "Таким образом, перед нами задача классификации. Для ее решения будем подход bag of words для векторизации текста и модели машинного обучения. Метрикой качества будет выступать F1-мера, результат должен быть не менее 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-kPcbpDlhbX"
   },
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CDrJYjlk6qi"
   },
   "source": [
    "### Классификация с помощью Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4qelsK1lGNJ"
   },
   "source": [
    "В начале создадим набор функций для очистки и лемматизации текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T21:41:21.682039Z",
     "iopub.status.busy": "2023-07-26T21:41:21.681370Z",
     "iopub.status.idle": "2023-07-26T21:41:22.912956Z",
     "shell.execute_reply": "2023-07-26T21:41:22.911939Z",
     "shell.execute_reply.started": "2023-07-26T21:41:21.682004Z"
    },
    "id": "KsbkZOtLAM3G"
   },
   "outputs": [],
   "source": [
    "# загрузка spacy с английским языком\n",
    "lemm_model = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "'''\n",
    "Функция принимает текст и лемматизирует его с помощью spacy\n",
    "'''\n",
    "def lemmatize(text):\n",
    "    doc = lemm_model(text)\n",
    "\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "'''\n",
    "Функция очищает текст, оставляет только английские буквы с нижним регистром и\n",
    "пробелы\n",
    "'''\n",
    "def clear_text(text):\n",
    "    text = re.sub(r'[^a-z ]', ' ', text)\n",
    "    text = text.split()\n",
    "\n",
    "    return ' '.join(text)\n",
    "\n",
    "'''\n",
    "Функция принимает датафрейм с признаком text и возвращает очищенный и\n",
    "лематизированный корпус\n",
    "'''\n",
    "def create_corp(df):\n",
    "    lowered = df['text'].str.lower() # все буквы к нижнему регистру\n",
    "    cleared = lowered.apply(clear_text) # очищение\n",
    "    lemmatized = cleared.apply(lemmatize) # лемматизация\n",
    "\n",
    "    return lemmatized.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# использование дампов\n",
    "try:\n",
    "    with open('train.bin', 'rb') as f:\n",
    "        corpus_train = pickle.load(f)\n",
    "        f.close()\n",
    "        \n",
    "    with open('test.bin', 'rb') as f:\n",
    "        corpus_test = pickle.load(f)\n",
    "        f.close()\n",
    "        \n",
    "    with open('valid.bin', 'rb') as f:\n",
    "        corpus_valid = pickle.load(f)\n",
    "        f.close()\n",
    "        \n",
    "except:\n",
    "    corpus_train = create_corp(train)\n",
    "    corpus_valid = create_corp(valid)\n",
    "    corpus_test = create_corp(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djqhF3iEyaIP"
   },
   "source": [
    "Вычислим TF-IDF для корпуса текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-26T21:49:30.976575Z",
     "iopub.status.busy": "2023-07-26T21:49:30.975639Z",
     "iopub.status.idle": "2023-07-26T21:49:33.081039Z",
     "shell.execute_reply": "2023-07-26T21:49:33.079705Z",
     "shell.execute_reply.started": "2023-07-26T21:49:30.976537Z"
    },
    "id": "FLfj8NXZHKqJ",
    "outputId": "1f2b0d76-82d9-4578-e449-8870a2797ea4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kirill.V.Gusev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# загрузка стоп-слов\n",
    "nltk.download('stopwords')\n",
    "stopwords = list(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим пайплайн для дальнейшей кросс-валидации без утечек данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Функция для подбора гиперпараметров.\n",
    "Принимает модель, вид поиска, признаки,, гиперпараметры для перебора и название модели для отображения.\n",
    "Строит пайплайн, запускает поиск гиперпараметров, выводит значения гиперпараметров и скор на обучении.\n",
    "Возвращает лучший пайплайн и лучшую метрику.\n",
    "\n",
    "search_type:\n",
    "C - cross_val_score\n",
    "G - GridSearchCV\n",
    "R - RandomizedSearchCV\n",
    "'''\n",
    "def pipe(model, search_type, X_train, y_train, params, name, cv=3):\n",
    "    \n",
    "    # ветка для cross_val_score\n",
    "    if search_type == \"C\":      \n",
    "        pipeline = make_pipeline(count_tf_idf, model)         \n",
    "        model_score = cross_val_score(\n",
    "            pipeline,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            scoring='f1',\n",
    "            cv=cv).mean()\n",
    "        # значение f1 на кросс-валидации\n",
    "        print(f'best_score: {model_score.round(3)}')\n",
    "        storage[name] = [model_score.round(3)]\n",
    "    \n",
    "        return pipeline, model_score\n",
    "    \n",
    "    # ветка для GridSearchCV\n",
    "    elif search_type == \"G\":\n",
    "        pipeline = make_pipeline(count_tf_idf, model)\n",
    "        gs = GridSearchCV(\n",
    "            pipeline, \n",
    "            param_grid=params, \n",
    "            scoring='f1', \n",
    "            n_jobs=-1,\n",
    "            error_score='raise',\n",
    "            verbose=2,\n",
    "            cv=cv\n",
    "        )        \n",
    "        gs.fit(X_train, y_train)\n",
    "        #лучшее значение f1 на кросс-валидации\n",
    "        print(f'best_score: {gs.best_score_.round(3)}')\n",
    "        # лучшие гиперпараметры\n",
    "        print(f'best_params: {gs.best_params_}')  \n",
    "        storage[name] = [gs.best_score_.round(3)] \n",
    "        \n",
    "        return gs.best_estimator_, gs.best_score_.round(3)\n",
    "    \n",
    "    # ветка для RandomizedSearchCV\n",
    "    elif search_type == \"R\":\n",
    "        pipeline = make_pipeline(count_tf_idf, model)\n",
    "        rs = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions=params, \n",
    "            scoring='f1', \n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            verbose=2,\n",
    "            cv=cv\n",
    "        )\n",
    "        rs.fit(X_train, y_train)\n",
    "        # лучшее значение f1 на кросс-валидации\n",
    "        print(f'best_score: {rs.best_score_.round(3)}')\n",
    "        # лучшие гиперпараметры\n",
    "        print(f'best_params: {rs.best_params_}')\n",
    "        storage[name] = [rs.best_score_.round(3)] \n",
    "\n",
    "        return rs.best_estimator_, rs.best_score_.round(3)\n",
    "        \n",
    "    else: print('Введите верный search_type')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель логистической регресии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "best_score: 0.787\n",
      "best_params: {'logisticregression__C': 100.0, 'tfidfvectorizer__ngram_range': (1, 2)}\n",
      "CPU times: total: 2min 52s\n",
      "Wall time: 8min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "storage = {}\n",
    "model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
    "\n",
    "param_grid_LR = {\n",
    "    \"tfidfvectorizer__ngram_range\": ((1, 1), (1, 2)),\n",
    "    'logisticregression__C': np.logspace(-1, 2, 7)}\n",
    "\n",
    "pipeline_LR, score_LR = pipe(\n",
    "    model,\n",
    "    'G',\n",
    "    corpus_train,\n",
    "    train['toxic'],\n",
    "    param_grid_LR,\n",
    "    'Linear Regression'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем улучшить метрику, перебирая пороговые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "функция выводит таблицу с пороговыми значениями и метрикой f1\n",
    "на вход подается обученная модель, признаки, целевой признак, правая граница порогов и шаг\n",
    "'''\n",
    "def f1_check(model, features, target, border, step):\n",
    "    proba = model.predict_proba(features)\n",
    "    proba_one = proba[:, 1]\n",
    "    temp_df = pd.DataFrame(columns=['f1_score', 'threshold'])\n",
    "    for threshold in np.arange(0, border, step):\n",
    "        predicted = proba_one > threshold\n",
    "        temp_df = pd.concat(\n",
    "            [temp_df, pd.DataFrame(\n",
    "                {'f1_score':f1_score(target, predicted),\n",
    "                 'threshold':threshold},index=[0])],\n",
    "            ignore_index=True)\n",
    "\n",
    "    return temp_df.sort_values(by='f1_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.787074</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.787007</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.786828</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.786718</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.786709</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score  threshold\n",
       "47  0.787074       0.47\n",
       "50  0.787007       0.50\n",
       "45  0.786828       0.45\n",
       "46  0.786718       0.46\n",
       "43  0.786709       0.43"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_check(pipeline_LR, corpus_valid, valid['toxic'], 1, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат лучше не стал. Проверим другие модели машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "best_score: 0.314\n",
      "best_params: {'randomforestclassifier__max_depth': 8, 'randomforestclassifier__n_estimators': 20, 'tfidfvectorizer__ngram_range': (1, 1)}\n",
      "CPU times: total: 15.9 s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "param_grid_RF = {\n",
    "    'tfidfvectorizer__ngram_range': ((1, 1), (1, 2)),\n",
    "    'randomforestclassifier__n_estimators': range(10, 30, 10),\n",
    "    'randomforestclassifier__max_depth': range(2, 10, 2)\n",
    "}\n",
    "\n",
    "pipeline_RF, score_RF = pipe(\n",
    "    model,\n",
    "    'G',\n",
    "    corpus_train,\n",
    "    train['toxic'],\n",
    "    param_grid_RF,\n",
    "    'Random Forest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель градиентного спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirill.V.Gusev\\.conda\\envs\\ds_practicum_env\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.755\n",
      "best_params: {'lgbmclassifier__learning_rate': 0.31622776601683794, 'lgbmclassifier__num_leaves': 40, 'tfidfvectorizer__ngram_range': (1, 2)}\n",
      "CPU times: total: 6min 38s\n",
      "Wall time: 16min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = lgb.LGBMClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'tfidfvectorizer__ngram_range': ((1, 1), (1, 2)),\n",
    "    'lgbmclassifier__num_leaves': range(10, 50, 10),\n",
    "    'lgbmclassifier__learning_rate': np.logspace(-1, 0, 5),\n",
    "}\n",
    "\n",
    "pipeline_lgbm, score_lgbm = pipe(\n",
    "    model,\n",
    "    'G',\n",
    "    corpus_train,\n",
    "    train['toxic'],\n",
    "    param_grid_lgbm,\n",
    "    \"LightGBM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z52hBdQuy0XV"
   },
   "source": [
    "Из каждого датафрейма получим признаки и целевой признак для обучения. Признак 'key_0' можно удалить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравнение и проверка на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_bAs_kWzQXO"
   },
   "source": [
    "Сравним результаты трех моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_9e305_row0_col0{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_9e305_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Cross-validation Score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_9e305_level0_row0\" class=\"row_heading level0 row0\" >Linear Regression</th>\n",
       "                        <td id=\"T_9e305_row0_col0\" class=\"data row0 col0\" >0.787</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e305_level0_row1\" class=\"row_heading level0 row1\" >Random Forest</th>\n",
       "                        <td id=\"T_9e305_row1_col0\" class=\"data row1 col0\" >0.314</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e305_level0_row2\" class=\"row_heading level0 row2\" >LightGBM</th>\n",
       "                        <td id=\"T_9e305_row2_col0\" class=\"data row2 col0\" >0.755</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c5e19465e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame(storage).T\n",
    "temp.columns = ['Cross-validation Score']\n",
    "temp.style.format(\"{:.3f}\").highlight_max(color='lightgreen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всех себя показала модель логистической регресии. Выведем для нее результат на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 45s\n",
      "Wall time: 2min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.793"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# обучение на увеличенной выборке train + test\n",
    "giga_train = np.concatenate((corpus_train, corpus_valid))\n",
    "giga_target = pd.concat([train['toxic'], valid['toxic']])\n",
    "\n",
    "pipeline_LR.fit(giga_train, giga_target)\n",
    "prediction = pipeline_LR.predict(corpus_test)\n",
    "f1_score(test['toxic'], prediction).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Условие задачи выполняется, метрика выше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXVArFgBlhba"
   },
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** В рамках решения задачи были выполнены следующие этапы:\n",
    "- проведены исследование и предобработка данных,\n",
    "- текст очищен и лемматизирован,\n",
    "- использован подход bag of words для конвертации слов в вектора,\n",
    "- проведена классификация с помощью моделей машинного обучения,\n",
    "- проведено сравнение резульатов.\n",
    "\n",
    "По итогам исследования выбрана модель логистической регрессии, так как она показала наилучшую метрику качества (более 75)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
